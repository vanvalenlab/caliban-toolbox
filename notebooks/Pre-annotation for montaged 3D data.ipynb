{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Prep for Crowd Annotation Pipeline (with montages)\n",
    "\n",
    "1. Collect raw data \n",
    "2. Adjust contrast of images\n",
    "3. Chop up images into manageable pieces\n",
    "4. Make into montages\n",
    "5. Upload to Figure8\n",
    "\n",
    "Files are named by these scripts such that the code blocks can run back-to-back with minimal input. For this reason, it is recommended that users run through the whole pipeline before processing another set of images.\n",
    "\n",
    "For annotation of 3D image sets (either z-stacks or timelapse) that do NOT require montages (which help to generate ground truth tracking training data), consider using the other pre-annotation pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import statements\n",
    "from __future__ import absolute_import\n",
    "\n",
    "import os\n",
    "\n",
    "from ipywidgets import fixed, interactive\n",
    "from skimage.io import imread\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "from deepcell_toolbox.pre_annotation.montage_makers import montage_maker, multiple_montage_maker\n",
    "from deepcell_toolbox.pre_annotation.overlapping_chopper import overlapping_crop_dir\n",
    "from deepcell_toolbox.pre_annotation.aws_upload import aws_upload, upload\n",
    "from deepcell_toolbox.pre_annotation.montage_to_csv import csv_maker\n",
    "from deepcell_toolbox.pre_annotation.fig_eight_upload import fig_eight\n",
    "from deepcell_toolbox.pre_annotation.contrast_adjustment import adjust_folder, adjust_overlay\n",
    "\n",
    "from deepcell_toolbox.utils.io_utils import get_img_names\n",
    "from deepcell_toolbox.utils.widget_utils import choose_img, edit_image, choose_img_pair, overlay_images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select base directory\n",
    "\n",
    "\"base_dir\" is a directory where several subfolders will be created to hold intermediate processed images and files. For example, at the start of this pipeline, \"/home/gnv/data/example\" might hold a few folders of images (different channels of the same dataset). By the end of this pipeline, it will also hold:\n",
    " - a folder for contrast-adjusted images \n",
    " - a folder for sub-images\n",
    " - a folder for montages\n",
    " - a folder that contains json files (store information about variables used to process images)\n",
    " - a folder that contains a CSV file to upload to Figure Eight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define path to desired base directory\n",
    "base_dir = \"/gnv_home/data/contrast_overlay_test/test2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sometimes raw images are in .tif stacks, not individual .tif files\n",
    "#optional code block for turning into individual slices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Adjust contrast of images\n",
    "Before doing anything else, we need to adjust the contrast of the raw data. The following section of this notebook allows the user to interactively choose how the raw images will be processed. The user should adjust the images to make them the most clear for annotators; these contrast-adjustment images will only be used for annotation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Option 1: Annotations of images, no overlays\n",
    "Some images, such as those of fluorescent nuclei, are relatively easy to annotate. Use the following code blocks to adjust the contrast of those images and save them. For more difficult data, such as cytoplasmic images, you may overlay two images (such as phase and fluorescence) to help guide annotators. To overlay images for annotation, skip to option 2.\n",
    "\n",
    "This widget will allow the user to adjust the following settings, then apply them to a directory of images:\n",
    " - \"blur\" changes a gaussian filter that blurs or sharpens the image\n",
    " - \"sobel_toggle\" determines if a sobel filter is applied on top of the original image; if on, the edges of objects in the image will have the highest contrast\n",
    " - \"sobel_factor\" changes how heavily the sobel filter is applied to the original image, if \"sobel_toggle\" is on\n",
    " - \"invert_img\"  inverts the intensity range of the image, so that the maximum value becomes the minimum, and vice versa\n",
    " - \"gamma_adjust\" changes the overall brightness of the image without interfering with histogram normalization of the image\n",
    "\n",
    " - \"equalize_hist\" - uses histogram equalization of the whole image to rescale pixel values\n",
    " - \"equalize_adapthist\" - uses histogram equalization applied to local regions of the image to rescale pixel values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define path to desired raw directory\n",
    "#base_dir = \"/gnv_home/data/contrast_overlay_test/test0\"\n",
    "raw_folder = \"DAPI\"\n",
    "identifier = \"test\"\n",
    "\n",
    "raw_dir = os.path.join(base_dir, raw_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose which raw image you would like to use to test on the contrast adjustment\n",
    "choose_raw = interactive(choose_img, name=get_img_names(raw_dir), dirpath =fixed(raw_dir));\n",
    "choose_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Test with choosen image to fix adjustment parameters\n",
    "img = imread(choose_raw.result)\n",
    "edit_raw = interactive(edit_image, image=fixed(img), blur=(0.0,4,0.1), gamma_adjust=(0.1,4,0.1), sobel_factor=(10,10000,100), v_min=(0,255,1), v_max=(0,255,1));\n",
    "edit_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# With choosen parameters, process all the raw data in the folder\n",
    "contrast_settings = edit_raw.kwargs\n",
    "\n",
    "#don't need this info to process images and can't be saved in json\n",
    "del contrast_settings['image']\n",
    "\n",
    "adjust_folder(base_dir, raw_folder, identifier, contrast_settings, is_2D = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Option 2: Overlay two images types for annotation\n",
    "First, define the folders where your images can be found. This assumes that the images you want to overlay are in separate subfolders. The directory the contains these subfolders, \"base_dir\", is where contrast adjusted images and subsequent processed images will be saved (each in an appropriate subfolder). The subfolders should contain the same number of images; they are expected to be different channels of the same original image.\n",
    "\n",
    "Next, a widget will load that allows you to scroll through the images contained in the source subfolders. The user can select a pair of images that are representative of the data set.\n",
    "\n",
    "Next, a widget will load that allows the user to adjust image processing settings for the first image in the pair (the \"raw\" image). After you are happy with the image, move on to the next code block; the settings you have determined will be saved.\n",
    " \n",
    "Next, a similar widget will load that allows the user to adjust the image that will be overlaid on the \"raw\" image. Once you are satisfied with this image, move on to the next code block; the settings you have determined will be saved.\n",
    " \n",
    "Next, a widget will load that allows the user to adjust how the images are overlaid. The user can specify the weighting of the overlay, and change the brightness settings of the final image to increase contrast. The two images to be overlaid can be readjusted individually if they need to be, by going back to the previous widgets and changing the settings. Just re-run the overlay widget and the new settings will be loaded.\n",
    " \n",
    "Finally, when you are satisfied with the adjustments made to the individual and overlaid images, running \"adjust_overlay\" will take the last-used settings from each widget, apply them to each image in the subfolders specified, and create an overlaid image. The adjusted images will be saved in a new folder; the original images will not be modified. The folder for the adjusted images will be named {raw}\\_overlay\\_{overlay} to indicate which source folders were combined."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define path to desired raw and overlay directories\n",
    "#base_dir = \"/gnv_home/data/contrast_overlay_test/test1\"\n",
    "raw_folder = \"FITC\"\n",
    "overlay_folder = \"phase\"\n",
    "identifier = \"test\"\n",
    "\n",
    "raw_path = os.path.join(base_dir, raw_folder)\n",
    "overlay_path = os.path.join(base_dir, overlay_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#pick a matched pair of images to adjust contrast\n",
    "#choose representative images for best results\n",
    "max_frame = len(get_img_names(raw_path))\n",
    "\n",
    "choose_pair = interactive(choose_img_pair, frame = (0, max_frame, 1), raw_dir = fixed(raw_path), overlay_dir = fixed(overlay_path), continuous_update = False);\n",
    "choose_pair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#adjust raw image\n",
    "raw_img = imread(choose_pair.result[0])\n",
    "edit_raw = interactive(edit_image, image=fixed(raw_img), blur=(0.0,4,0.1), gamma_adjust=(0.1,4,0.1), sobel_factor=(10,10000,100), v_min=(0,255,1), v_max=(0,255,1));\n",
    "edit_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#adjust overlay image\n",
    "overlay_img = imread(choose_pair.result[1])\n",
    "edit_overlay = interactive(edit_image, image=fixed(overlay_img), blur=(0.0,4,0.1), gamma_adjust=(0.1,4,0.1), sobel_factor=(10,10000,100), v_min=(0,255,1), v_max=(0,255,1));\n",
    "edit_overlay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#overlay images\n",
    "raw_adjusted = edit_raw.result\n",
    "overlay_adjusted = edit_overlay.result\n",
    "edit_combination = interactive(overlay_images, raw_img = fixed(raw_adjusted), overlay_img =fixed(overlay_adjusted), prop_raw =(0,1.0, 0.1), v_min = (0, 255, 1), v_max = (0, 255, 1))\n",
    "edit_combination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#apply overlay settings to all images in folder\n",
    "#modified images are saved to new folder and do not overwrite originals\n",
    "raw_settings = edit_raw.kwargs\n",
    "del raw_settings['image']\n",
    "overlay_settings = edit_overlay.kwargs\n",
    "del overlay_settings['image']\n",
    "combined_settings = edit_combination.kwargs\n",
    "del combined_settings['overlay_img']\n",
    "del combined_settings['raw_img']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "adjust_overlay(base_dir, raw_folder, overlay_folder, identifier, raw_settings, overlay_settings, combined_settings, is_2D = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Chop up images into manageable pieces\n",
    "\n",
    "Each full-size image usually has many cells in it. This makes them difficult to fully annotate! For ease of annotation (and better results), each frame is chopped up into smaller, overlapping frames, ultimately creating a set of movies. \n",
    "\n",
    "These smaller movies can be made with overlapping edges, making it easier to stitch annotations together into one large annotated movie (in the post-annotation pipeline). A large overlap will result in redundant annotations.\n",
    "\"is_2D\" toggles between two modes of naming chopped images.\n",
    "\n",
    "Even if you want to make montages with the full-sized image (not recommended), run the chopper with num_segments of 1. The montage makers are written to run on the output of the chopper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_input_folder = \"FITC_overlay_phase\"\n",
    "image_input_dir = os.path.join(base_dir, image_input_folder)\n",
    "\n",
    "num_x_segments = 4\n",
    "num_y_segments = 4\n",
    "overlap_perc = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "overlapping_crop_dir(image_input_dir, identifier, num_x_segments, num_y_segments, overlap_perc, is_2D = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Make into montages\n",
    "multiple_montage_maker is written to run on the output of the chopper, ie the folder where each chopped movie folder is saved. It will make montages of each subfolder according to the variables specified. It will make more than one montage per subfolder if there are enough frames to do so.\n",
    "\n",
    " - \"chopped_dir\" is the path to the folder where chopped images were saved; this folder was created by overlapping_crop_dir, so the user should not change this variable if they are going straight through the pipeline\n",
    " - \"save_dir\" is the path to a folder where the montages will be saved; this folder will be created by multiple_montage_maker, and the user generally will not need to change this path\n",
    " - \"log_dir\" is where the json log containing information about the inputs to the montage maker will be saved\n",
    " - \"montage_len\" specifies how many frames the montage will hold\n",
    " - \"row_length\" specifies how many frames will be in each row of the montage\n",
    " - \"x_buffer\" specifies how many pixels of padding will separate each column of images\n",
    " - \"y_buffer\" specifies how many pixels of padding will separate each row of images\n",
    "\n",
    "The variables used in multiple_montage_maker are saved in a JSON file so they can be reused in post-annotation processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "chopped_dir = image_input_dir + \"_chopped_\" + str(num_x_segments) + \"_\" + str(num_y_segments)\n",
    "#chopped_dir = \"/home/gnv/data/example/FITC_overlay_phase_chopped_4_4\"\n",
    "\n",
    "save_dir = os.path.join(base_dir, identifier + \"_montages_\" + str(num_x_segments) + \"_\" + str(num_y_segments))\n",
    "#save_dir = \"/home/gnv/data/example/montages\"\n",
    "\n",
    "log_dir = os.path.join(base_dir, \"json_logs\")\n",
    "\n",
    "montage_len = 10\n",
    "row_length = 10\n",
    "x_buffer = 20\n",
    "y_buffer = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "multiple_montage_maker(montage_len, chopped_dir, save_dir, identifier, \n",
    "                       num_x_segments, num_y_segments, row_length, x_buffer, y_buffer, log_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Upload to Figure Eight\n",
    "Now that the images are processed into montages, they need to be uploaded to an AWS bucket and submitted to Figure Eight. This involves uploading the files to AWS, making a CSV file with the links to the uploaded images, and using that CSV file to create a Figure Eight job."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Upload files to AWS\n",
    "aws_upload will look for image files in the specified directory (folder_to_upload, set by default to be wherever the output of multiple_montage_maker was saved) and upload them into a bucket. If you don't want to include all of the montages you have made in the figure eight job, move the montages of interest to a new folder and upload that.\n",
    "\n",
    "For the Van Valen lab, the default bucket is \"figure-eight-deepcell\" and keys (aws_folder + file names) correspond to the file structure of our data server.\n",
    "\n",
    "aws_upload returns a list of the urls to which images were uploaded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "bucket_name = \"figure-eight-deepcell\" #default\n",
    "aws_folder = \"gnv/data/example\"\n",
    "folder_to_upload = save_dir\n",
    "#folder_to_upload = \"/home/gnv/data/example/only_some_of_the_montages\"\n",
    "\n",
    "uploaded_montages = aws_upload(bucket_name, aws_folder, folder_to_upload)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make CSV file\n",
    "Figure Eight jobs can be created easily by using a CSV file where each row contains information about one task. For our jobs, each row has the link to the location of one montage, and information about that montage (currently, just the \"identifier\" specified at the beginning of the pipeline). The CSV file is saved as \"identifier\".csv in a folder that only holds CSVs. CSV folders are usually in cell-type directories, so identifiers should be able to distinguish between sets, parts, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_dir = os.path.join(base_dir, \"CSV\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_maker(uploaded_montages, identifier, csv_dir, context = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Figure Eight job\n",
    "The Figure Eight API allows us to create a new job and upload data to it from this notebook. However, since our jobs don't include required test questions, editing job information such as the title of the job must be done via the website. This section of the notebook uses the API to create a job and upload data to it, then reminds the user to finish editing the job on the website.\n",
    "\n",
    "Some sample job IDs to copy are provided below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#job_id_to_copy = 1344258 #Elowitz timelapse RFP pilot\n",
    "job_id_to_copy = 1346216 #Deepcell MouseBrain 3x5\n",
    "#job_id_to_copy = 1306431 #Deepcell overlapping Mibi\n",
    "#job_id_to_copy = 1292179 #Deepcell HEK\n",
    "#job_id_to_copy = 1363594 #3T3 cytoplasm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_eight(csv_dir, identifier, job_id_to_copy)"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
