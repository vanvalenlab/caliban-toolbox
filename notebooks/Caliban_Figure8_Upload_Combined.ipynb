{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Caliban Fig8 Processing Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import statements\n",
    "from __future__ import absolute_import\n",
    "\n",
    "from segmentation.utils import data_utils\n",
    "from imageio import imread, volread, imwrite, volwrite\n",
    "import numpy as np\n",
    "import os\n",
    "import stat\n",
    "import sys\n",
    "\n",
    "\n",
    "import skimage.io as io\n",
    "\n",
    "from caliban_toolbox.pre_annotation import npz_preprocessing\n",
    "from caliban_toolbox.post_annotation import npz_postprocessing\n",
    "from caliban_toolbox.pre_annotation.aws_upload import aws_caliban_upload\n",
    "from caliban_toolbox.pre_annotation.caliban_csv import initial_csv_maker, create_next_CSV\n",
    "from caliban_toolbox.pre_annotation.fig_eight_upload import fig_eight\n",
    "\n",
    "\n",
    "\n",
    "from ipywidgets import fixed, interactive\n",
    "%matplotlib inline\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from skimage import filters, img_as_uint\n",
    "import skimage as sk\n",
    "import xarray as xr\n",
    "\n",
    "from caliban_toolbox.utils.io_utils import get_img_names\n",
    "from caliban_toolbox.utils import widget_utils\n",
    "\n",
    "perm_mod = stat.S_IRWXO | stat.S_IRWXU | stat.S_IRWXG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data for model training\n",
    "We'll specify which channels will be used to generate preliminary labels for the model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3D data example:\n",
    "# data_dir = '/example_data/3D/FOV_0'\n",
    "# data_vol = os.path.join(data_dir, 'Pos0_DAPIRegistered.tif')\n",
    "# data_stack_values = volread(data_vol)\n",
    "# data_stack_values = np.expand_dims(data_stack_values, axis=-1)\n",
    "\n",
    "\n",
    "# # convert to xarray\n",
    "# fov_names = [\"slice_\" + str(x) for x in range(data_stack_values.shape[0])]\n",
    "# channel_names = [\"DAPI\"]\n",
    "# data_stack_xr = xr.DataArray(data_stack_values, coords=[fov_names, range(data_stack_values.shape[1]),\n",
    "#                                                 range(data_stack_values.shape[2]), channel_names],\n",
    "#                             dims=[\"fovs\", \"rows\", \"cols\", \"channels\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# time series data example\n",
    "data_stack_xr = data_utils.load_tifs_from_points_dir(\"/example_data/timelapse/HeLa_by_image\", \n",
    "                                                  points=os.listdir(\"/example_data/timelapse/HeLa_by_image\"),\n",
    "                                                 tifs=[\"FITC_001.png\", \"Phase_000.png\", \"Phase_001.png\", \"Phase_002.png\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # mibi data example\n",
    "# data_stack_xr = data_utils.load_tifs_from_points_dir(\"/example_data/multichannel/Training_Data_1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the data through the network to produce labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# deepcell upload code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Postprocess the deepcell labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code to postprocess labels, select appropriate parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part A: Adjust image contrast, background, thresholding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize lists to hold newly created channels\n",
    "adjusted_channels, adjusted_channel_names, adjusted_channel_kwargs = [], [], []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Pick raw image\n",
    "This will be used as an example to display effect of adjustments later on. This can be changed at any time!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb0a7dabda224db2a4911ea0eb1f2d87",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=2, description='slice_idx', max=4), Dropdown(description='chan_name', op…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "choose_img_output = interactive(widget_utils.choose_img_from_stack, stack = fixed(data_stack_xr), \n",
    "                         slice_idx = (0, data_stack_xr.shape[0]-1, 1),\n",
    "                         chan_name = (data_stack_xr.channels.values));\n",
    "choose_img_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Set raw image adjust parameters\n",
    "These will be held in memory until npz is saved. A record of the contrast adjustment settings will be saved with them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0621b59e31844758adf6a1785e6ef9e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(FloatSlider(value=1.0, description='blur', max=4.0), Checkbox(value=True, description='s…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# get most recent parameters for selected image\n",
    "selected_slice_idx, selected_channel_idx = choose_img_output.result\n",
    "img = data_stack_xr[selected_slice_idx, :, :, selected_channel_idx]\n",
    "\n",
    "# interative edit mode\n",
    "adjust_image_output = interactive(widget_utils.adjust_image_interactive, image=fixed(img), blur=(0.0,4,0.1), \n",
    "                       gamma_adjust=(0.1,4,0.1), sobel_factor=(10,10000,100), v_min = (0, 255, 1), \n",
    "                       v_max = (0, 255, 1));\n",
    "adjust_image_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Adjust raw image with specified parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create placeholder channel to hold the output of channel adjustment\n",
    "adjusted_channel_xr = xr.DataArray(np.zeros(data_stack_xr.shape[:-1] + (1,), np.uint8),\n",
    "                                   coords=[data_stack_xr.points, data_stack_xr.rows, data_stack_xr.cols,\n",
    "                                          [\"adjusted_channel\"]],\n",
    "                                   dims=data_stack_xr.dims)\n",
    "\n",
    "# adjust all slices for given channel\n",
    "for i in range(data_stack_xr.shape[0]):\n",
    "    image = data_stack_xr[i, :, :, selected_channel_idx]\n",
    "    adjusted_channel_xr[i, :, :, 0] = widget_utils.adjust_image(image, adjust_image_output.kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Verify that adjustment looks good across slices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c7c76c2697f44724b4370741703dcc89",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=2, description='slice_idx', max=4), Output()), _dom_classes=('widget-int…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "check_adjustment_output = interactive(widget_utils.choose_img_from_stack, stack = fixed(adjusted_channel_xr), \n",
    "                               slice_idx = (0, data_stack_xr.shape[0]-1, 1),\n",
    "                              chan_name = fixed(\"adjusted_channel\"));\n",
    "check_adjustment_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Give the adjusted channel an informative name, repeat part A for each channel that needs to be adjusted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "adjusted_channel_name = \"phase_contrast_adjusted\"\n",
    "adjusted_channel_names.append(adjusted_channel_name)\n",
    "adjusted_channels.append(adjusted_channel_xr.values)\n",
    "adjusted_channel_kwargs.append(adjust_image_output.kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part B: create overlays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize lists to hold newly created channels\n",
    "overlay_channels, overlay_channel_names, overlay_channel_kwargs = [], [], []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Select first channel to be included in overlay, perform any needed adjustments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['FITC_001', 'Phase_000', 'Phase_001', 'Phase_002'], dtype='<U9')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# available channels\n",
    "data_stack_xr.channels.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a83a59d89194e0c80fd200aeafa1246",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(FloatSlider(value=1.0, description='blur', max=4.0), Checkbox(value=True, description='s…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "img_1_idx = 0\n",
    "img1 = data_stack_xr[selected_slice_idx, :, :, img_1_idx]\n",
    "\n",
    "adjust_overlay_1_output = interactive(widget_utils.adjust_image_interactive, image=fixed(img1), blur=(0.0,4,0.1), \n",
    "                          gamma_adjust=(0.1,4,0.1), sobel_factor=(10,10000,100), v_min = (0, 255, 1), \n",
    "                          v_max = (0, 255, 1));\n",
    "adjust_overlay_1_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Select second channel to be included in overlay, perform any needed adjustments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d7c59af75484d3689098d1353f89d92",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(FloatSlider(value=1.0, description='blur', max=4.0), Checkbox(value=True, description='s…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "img_2_idx = 3\n",
    "img2 = data_stack_xr[selected_slice_idx, :, :, img_2_idx]\n",
    "\n",
    "adjust_overlay_2_output = interactive(widget_utils.adjust_image_interactive, image=fixed(img2), blur=(0.0,4,0.1), \n",
    "                          gamma_adjust=(0.1,4,0.1), sobel_factor=(2,10000,100), v_min = (0, 255, 1), \n",
    "                          v_max = (0, 255, 1));\n",
    "adjust_overlay_2_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Select the appropriate settings for combinging the two images together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a848489ec4fb455d8ba33ac604ead477",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(FloatSlider(value=0.5, description='prop_img_1', max=1.0), IntSlider(value=0, descriptio…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "overlay_images_output = interactive(widget_utils.overlay_images_interactive, \n",
    "                               img_1 = fixed(adjust_overlay_1_output.result), \n",
    "                               img_2 = fixed(adjust_overlay_2_output.result), \n",
    "                               prop_img_1 =(0,1.0, 0.1), v_min = (0, 255, 1), v_max = (0, 255, 1))\n",
    "overlay_images_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Create overlays across the whole image stack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract settings from interactive job\n",
    "combined_settings = overlay_images_output.kwargs\n",
    "prop_img_1 = combined_settings['prop_img_1']\n",
    "v_min = combined_settings['v_min']\n",
    "v_max = combined_settings['v_max']\n",
    "\n",
    "overlay_channel_xr = xr.DataArray(np.zeros(data_stack_xr.shape[:-1] + (1,), np.uint8),\n",
    "                                   coords=[data_stack_xr.points, data_stack_xr.rows, data_stack_xr.cols,\n",
    "                                          [\"overlay_channel\"]],\n",
    "                                   dims=data_stack_xr.dims)\n",
    "\n",
    "# apply settings across images in stack\n",
    "for i in range(data_stack_xr.shape[0]):\n",
    "    image1 = data_stack_xr[i, :, :, img_1_idx]\n",
    "    image2 = data_stack_xr[i, :, :, img_2_idx]\n",
    "\n",
    "    image1_adjusted = widget_utils.adjust_image(image1, adjust_overlay_1_output.kwargs)\n",
    "    image2_adjusted = widget_utils.adjust_image(image2, adjust_overlay_2_output.kwargs)\n",
    "    overlay_channel_xr[i, :, :, 0] = widget_utils.overlay_images(image1_adjusted, image1_adjusted, \n",
    "                                                              prop_img_1, v_min, v_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a9149633454e4988aad8cda00cdfe7a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=2, description='slice_idx', max=4), Output()), _dom_classes=('widget-int…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "check_adjustment = interactive(widget_utils.choose_img_from_stack, stack = fixed(overlay_channel_xr), \n",
    "                         slice_idx = (0, data_stack_xr.shape[0]-1, 1),\n",
    "                         chan_name = fixed(\"overlay_channel\"));\n",
    "check_adjustment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Give the combined channel an informative name, repeat part B for each set of overlays that needs to be constructed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# give this overlay an informative name\n",
    "overlay_channel_name = \"phase_0_phase_3_overlay\"\n",
    "\n",
    "# add metadata to list\n",
    "overlay_channel_names.append(overlay_channel_name)\n",
    "overlay_channels.append(overlay_channel_xr.values)\n",
    "adjusted_channel_kwargs.append([prop_img_1, v_min, v_max, adjust_overlay_1_output.kwargs, adjust_overlay_2_output])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part C: Determine which modified channels will be included and in what order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concatenate all adjusted channels together\n",
    "adjusted_channel_stack = np.concatenate(adjusted_channels, axis=-1)\n",
    "\n",
    "# concatenate all overlayed channels together\n",
    "overlay_channel_stack = np.concatenate(overlay_channels, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine original channels and new channels together\n",
    "all_channel_stack = np.concatenate((data_stack_xr.values, adjusted_channel_stack, overlay_channel_stack), axis=-1)\n",
    "all_channel_names = np.concatenate((data_stack_xr.channels.values, \n",
    "                                    adjusted_channel_names, overlay_channel_names), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create labeled xarray to hold all data\n",
    "all_channels = xr.DataArray(all_channel_stack, coords=[data_stack_xr.points, data_stack_xr.rows,\n",
    "                                                      data_stack_xr.cols, all_channel_names],\n",
    "                           dims=[\"points\", \"rows\", \"cols\", \"channels\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify subset of above channels to be incldued, as well as their ordering\n",
    "channel_order = [\"phase_contrast_adjusted\", \"FITC_001\", \"Phase_002\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_xr = data_utils.reorder_xarray_channels(channel_order=channel_order, channel_xr=all_channels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part D: Set shape of NPZ files for optimum annotator ease"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Crop array into overlapping x and y crops\n",
    "Split an array up into smaller crops that overlap one another"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('fovs', 'points', 'rows', 'cols', 'channels')"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create montages across 3D or timelapse slices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first add in any missing dimensions to standardize format\n",
    "reshaped_xr = npz_postprocessing.reshape_xr(final_xr, [\"fovs\", \"points\", \"rows\", \"cols\", \"channels\",])\n",
    "\n",
    "# determine how many slices per montage\n",
    "montage_slice_len = 2\n",
    "\n",
    "montage_xr, montage_indices = npz_preprocessing.create_montage_data(reshaped_xr, montage_slice_len)\n",
    "npz_preprocessing.save_npzs_for_caliban(montage_xr, montage_indices, \"/example_data/timelapse/HeLa_by_image_montaged\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Relabel npzs -- recommended for fig8 first pass jobs\n",
    "\"Predict\" relabeling is recommended (unless 3D segmentation models are being used), since this relabeling strategy will perform decently on most 3D data to reduce the human labor involved in correction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# not sure what this is for?\n",
    "# relabel_npzs_folder(npz_dir = sliced_save_dir, relabel_type = 'predict')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
