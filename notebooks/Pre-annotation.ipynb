{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Prep for Crowd Annotation Pipeline\n",
    "\n",
    "1. Collect raw data \n",
    "2. Adjust contrast of images\n",
    "3. Chop up images into manageable pieces\n",
    "4. Make into montages\n",
    "5. Upload to Figure8\n",
    "\n",
    "Files are named by these scripts such that the code blocks can run back-to-back with minimal input. For this reason, it is recommended that users run through the whole pipeline before processing another set of images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import statements\n",
    "from __future__ import absolute_import\n",
    "\n",
    "import os\n",
    "\n",
    "from ipywidgets import fixed, interactive\n",
    "from skimage.io import imread\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "from dcde.pre_annotation.montage_makers import montage_maker, multiple_montage_maker\n",
    "from dcde.pre_annotation.overlapping_chopper import overlapping_crop_dir\n",
    "from dcde.pre_annotation.aws_upload import aws_upload, upload\n",
    "from dcde.pre_annotation.montage_to_csv import csv_maker\n",
    "from dcde.pre_annotation.fig_eight_upload import fig_eight\n",
    "from dcde.pre_annotation.contrast_adjustment import adjust_folder, adjust_overlay\n",
    "\n",
    "from dcde.utils.io_utils import get_img_names\n",
    "from dcde.utils.widget_utils import choose_img, edit_image, choose_img_pair, overlay_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sometimes raw images are in .tif stacks, not individual .tif files\n",
    "#optional code block for turning into individual slices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Adjust contrast of images\n",
    "Before doing anything else, we need to adjust the contrast of the raw data. The following section of this notebook allows the user to interactively choose how the raw images will be processed. The user should adjust the images to make them the most clear for annotators; these contrast-adjustment images will only be used for annotation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Option 1: Annotations of images, no overlays\n",
    "Some images, such as those of fluorescent nuclei, are relatively easy to annotate. Use the following code blocks to adjust the contrast of those images and save them. For more difficult data, such as cytoplasmic images, you may overlay two images (such as phase and fluorescence) to help guide annotators. To overlay images for annotation, skip to option 2.\n",
    "\n",
    "This widget will allow the user to adjust the following settings, then apply them to a directory of images:\n",
    " - \"blur\" changes a gaussian filter that blurs or sharpens the image\n",
    " - \"sobel_toggle\" determines if a sobel filter is applied on top of the original image; if on, the edges of objects in the image will have the highest contrast\n",
    " - \"sobel_factor\" changes how heavily the sobel filter is applied to the original image, if \"sobel_toggle\" is on\n",
    " - \"invert_img\"  inverts the intensity range of the image, so that the maximum value becomes the minimum, and vice versa\n",
    " - \"gamma_adjust\" changes the overall brightness of the image without interfering with histogram normalization of the image\n",
    "\n",
    " - \"equalize_hist\" - uses histogram equalization of the whole image to rescale pixel values\n",
    " - \"equalize_adapthist\" - uses histogram equalization applied to local regions of the image to rescale pixel values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define path to desired raw directory\n",
    "base_dir = \"/home/gnv/data/example\"\n",
    "raw_folder = \"raw\"\n",
    "identifier = \"notebook_example\"\n",
    "\n",
    "raw_dir = os.path.join(base_dir, raw_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose which raw image you would like to use to test on the contrast adjustment\n",
    "choose_raw = interactive(choose_img, name=get_img_names(raw_dir), dirpath =fixed(raw_dir));\n",
    "choose_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Test with choosen image to fix adjustment parameters\n",
    "img = imread(choose_raw.result)\n",
    "edit_raw = interactive(edit_image, image=fixed(img), blur=(0.0,4,0.1), gamma_adjust=(0.1,4,0.1), sobel_factor=(10,10000,100));\n",
    "edit_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# With choosen parameters, process all the raw data in the folder\n",
    "sigma = edit_raw.kwargs['blur']\n",
    "hist = edit_raw.kwargs['equalize_hist']\n",
    "adapthist = edit_raw.kwargs['equalize_adapthist']\n",
    "gamma = edit_raw.kwargs['gamma_adjust']\n",
    "sobel_option = edit_raw.kwargs['sobel_toggle']\n",
    "sobel = edit_raw.kwargs['sobel_factor']\n",
    "invert = edit_raw.kwargs['invert_img']\n",
    "\n",
    "adjust_folder(base_dir, raw_folder, identifier, sigma, hist, adapthist, gamma, sobel_option, sobel, invert)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Option 2: Overlay two images types for annotation\n",
    "First, define the folders where your images can be found. This assumes that the images you want to overlay are in separate subfolders. The directory the contains these subfolders, \"base_dir\", is where contrast adjusted images and subsequent processed images will be saved (each in an appropriate subfolder). The subfolders should contain the same number of images; they are expected to be different channels of the same original image.\n",
    "\n",
    "Next, a widget will load that allows you to scroll through the images contained in the source subfolders. The user can select a pair of images that are representative of the data set.\n",
    "\n",
    "Next, a widget will load that allows the user to adjust image processing settings for the first image in the pair (the \"raw\" image). After you are happy with the image, move on to the next code block; the settings you have determined will be saved.\n",
    " \n",
    "Next, a similar widget will load that allows the user to adjust the image that will be overlaid on the \"raw\" image. Once you are satisfied with this image, move on to the next code block; the settings you have determined will be saved.\n",
    " \n",
    "Next, a widget will load that allows the user to adjust how the images are overlaid. The user can specify the weighting of the overlay, and change the brightness settings of the final image to increase contrast. The two images to be overlaid can be readjusted individually if they need to be, by going back to the previous widgets and changing the settings. Just re-run the overlay widget and the new settings will be loaded.\n",
    " \n",
    "Finally, when you are satisfied with the adjustments made to the individual and overlaid images, running \"adjust_overlay\" will take the last-used settings from each widget, apply them to each image in the subfolders specified, and create an overlaid image. The adjusted images will be saved in a new folder; the original images will not be modified. The folder for the adjusted images will be named {raw}\\_overlay\\_{overlay} to indicate which source folders were combined."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define path to desired raw and overlay directories\n",
    "base_dir = \"/home/gnv/data/example\"\n",
    "raw_folder = \"FITC\"\n",
    "overlay_folder = \"phase\"\n",
    "identifier = \"overlay_example\"\n",
    "\n",
    "raw_path = os.path.join(base_dir, raw_folder)\n",
    "overlay_path = os.path.join(base_dir, overlay_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#pick a matched pair of images to adjust contrast\n",
    "#choose representative images for best results\n",
    "max_frame = len(get_img_names(raw_path))\n",
    "\n",
    "choose_pair = interactive(choose_img_pair, frame = (0, max_frame, 1), raw_dir = fixed(raw_path), overlay_dir = fixed(overlay_path), continuous_update = False);\n",
    "choose_pair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#adjust raw image\n",
    "raw_img = imread(choose_pair.result[0])\n",
    "edit_raw = interactive(edit_image, image=fixed(raw_img), blur=(0.0,4,0.1), gamma_adjust=(0.1,4,0.1), sobel_factor=(10,10000,100));\n",
    "edit_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#adjust overlay image\n",
    "overlay_img = imread(choose_pair.result[1])\n",
    "edit_overlay = interactive(edit_image, image=fixed(overlay_img), blur=(0.0,4,0.1), gamma_adjust=(0.1,4,0.1), sobel_factor=(10,10000,100));\n",
    "edit_overlay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#overlay images\n",
    "raw_adjusted = edit_raw.result\n",
    "overlay_adjusted = edit_overlay.result\n",
    "edit_combination = interactive(overlay_images, raw_img = fixed(raw_adjusted), overlay_img =fixed(overlay_adjusted), prop_raw =(0,1.0, 0.1), v_min = (0, 255, 1), v_max = (0, 255, 1))\n",
    "edit_combination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#apply overlay settings to all images in folder\n",
    "#modified images are saved to new folder and do not overwrite originals\n",
    "raw_settings = edit_raw.kwargs\n",
    "overlay_settings = edit_overlay.kwargs\n",
    "combined_settings = edit_combination.kwargs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "adjust_overlay(base_dir, raw_folder, overlay_folder, identifier, raw_settings, overlay_settings, combined_settings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Chop up images into manageable pieces\n",
    "\n",
    "Each full-size image usually has many cells in it. This makes them difficult to fully annotate! For ease of annotation (and better results), each frame is chopped up into smaller, overlapping frames, ultimately creating a set of movies. \n",
    "\n",
    "These smaller movies can be made with overlapping edges, making it easier to stitch annotations together into one large annotated movie (in the post-annotation pipeline). A large overlap will result in redundant annotations.\n",
    "\n",
    "Even if you want to process the full-sized image, run the chopper with num_segments of 1. The montage makers are written to run on the output of the chopper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_input_folder = \"FITC_overlay_phase\"\n",
    "image_input_dir = os.path.join(base_dir, image_input_folder)\n",
    "\n",
    "num_x_segments = 4\n",
    "num_y_segments = 4\n",
    "overlap_perc = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "overlapping_crop_dir(image_input_dir, identifier, num_x_segments, num_y_segments, overlap_perc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Make into montages\n",
    "multiple_montage_maker is written to run on the output of the chopper, ie the folder where each chopped movie folder is saved. It will make montages of each subfolder according to the variables specified. It will make more than one montage per subfolder if there are enough frames to do so.\n",
    "\n",
    " - \"chopped_dir\" is the path to the folder where chopped images were saved; this folder was created by overlapping_crop_dir, so the user should not change this variable if they are going straight through the pipeline\n",
    " - \"save_dir\" is the path to a folder where the montages will be saved; this folder will be created by multiple_montage_maker, and the user generally will not need to change this path\n",
    " - \"log_dir\" is where the json log containing information about the inputs to the montage maker will be saved\n",
    " - \"montage_len\" specifies how many frames the montage will hold\n",
    " - \"row_length\" specifies how many frames will be in each row of the montage\n",
    " - \"x_buffer\" specifies how many pixels of padding will separate each column of images\n",
    " - \"y_buffer\" specifies how many pixels of padding will separate each row of images\n",
    "\n",
    "The variables used in multiple_montage_maker are saved in a JSON file so they can be reused in post-annotation processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "chopped_dir = image_input_dir + \"_chopped_\" + str(num_x_segments) + \"_\" + str(num_y_segments)\n",
    "#chopped_dir = \"/home/gnv/data/example/FITC_overlay_phase_chopped_4_4\"\n",
    "\n",
    "save_dir = os.path.join(base_dir, identifier + \"_montages_\" + str(num_x_segments) + \"_\" + str(num_y_segments))\n",
    "#save_dir = \"/home/gnv/data/example/montages\"\n",
    "\n",
    "log_dir = os.path.join(base_dir, \"json_logs\")\n",
    "\n",
    "montage_len = 10\n",
    "row_length = 10\n",
    "x_buffer = 20\n",
    "y_buffer = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "multiple_montage_maker(montage_len, chopped_dir, save_dir, identifier, \n",
    "                       num_x_segments, num_y_segments, row_length, x_buffer, y_buffer, log_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Upload to Figure Eight\n",
    "Now that the images are processed into montages, they need to be uploaded to an AWS bucket and submitted to Figure Eight. This involves uploading the files to AWS, making a CSV file with the links to the uploaded images, and using that CSV file to create a Figure Eight job."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Upload files to AWS\n",
    "aws_upload will look for image files in the specified directory (folder_to_upload, set by default to be wherever the output of multiple_montage_maker was saved) and upload them into a bucket. If you don't want to include all of the montages you have made in the figure eight job, move the montages of interest to a new folder and upload that.\n",
    "\n",
    "For the Van Valen lab, the default bucket is \"figure-eight-deepcell\" and keys (aws_folder + file names) correspond to the file structure of our data server.\n",
    "\n",
    "aws_upload returns a list of the urls to which images were uploaded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "bucket_name = \"figure-eight-deepcell\" #default\n",
    "aws_folder = \"gnv/data/example\"\n",
    "folder_to_upload = save_dir\n",
    "#folder_to_upload = \"/home/gnv/data/example/only_some_of_the_montages\"\n",
    "\n",
    "uploaded_montages = aws_upload(bucket_name, aws_folder, folder_to_upload)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make CSV file\n",
    "Figure Eight jobs can be created easily by using a CSV file where each row contains information about one task. For our jobs, each row has the link to the location of one montage, and information about that montage (currently, just the \"identifier\" specified at the beginning of the pipeline). The CSV file is saved as \"identifier\".csv in a folder that only holds CSVs. CSV folders are usually in cell-type directories, so identifiers should be able to distinguish between sets, parts, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_dir = os.path.join(base_dir, \"CSV\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_maker(uploaded_montages, identifier, csv_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Figure Eight job\n",
    "The Figure Eight API allows us to create a new job and upload data to it from this notebook. However, since our jobs don't include required test questions, editing job information such as the title of the job must be done via the website. This section of the notebook uses the API to create a job and upload data to it, then reminds the user to finish editing the job on the website.\n",
    "\n",
    "Some sample job IDs to copy are provided below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#job_id_to_copy = 1344258 #Elowitz timelapse RFP pilot\n",
    "job_id_to_copy = 1346216 #Deepcell MouseBrain 3x5\n",
    "#job_id_to_copy = 1306431 #Deepcell overlapping Mibi\n",
    "#job_id_to_copy = 1292179 #Deepcell HEK\n",
    "#job_id_to_copy = 1363594 #3T3 cytoplasm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_eight(csv_dir, identifier, job_id_to_copy)"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
