{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Prep for Crowd Annotation Pipeline\n",
    "\n",
    "1. Collect raw data \n",
    "2. Adjust contrast of images\n",
    "3. Chop up images into manageable pieces\n",
    "4. Make into montages\n",
    "5. Upload to Figure8\n",
    "\n",
    "Files are named by these scripts such that the code blocks can run back-to-back with minimal input. For this reason, it is recommended that users run through the whole pipeline before processing another set of images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import statements\n",
    "from __future__ import absolute_import\n",
    "\n",
    "from ipywidgets import interact, fixed, interactive\n",
    "import numpy as np\n",
    "import skimage as sk\n",
    "import os\n",
    "from scipy import ndimage\n",
    "import scipy\n",
    "import sys\n",
    "from skimage.io import imread\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import scipy.ndimage as ndi\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "from dcde.pre_annotation.montage_makers import montage_maker, multiple_montage_maker\n",
    "from dcde.pre_annotation.overlapping_chopper import overlapping_crop_dir\n",
    "from dcde.pre_annotation.aws_upload import aws_upload, upload\n",
    "from dcde.pre_annotation.montage_to_csv import csv_maker\n",
    "from dcde.pre_annotation.fig_eight_upload import fig_eight\n",
    "from dcde.pre_annotation.contrast_adjustment import contrast, adjust_folder, adjust_overlay\n",
    "\n",
    "from dcde.utils.io_utils import get_img_names\n",
    "from dcde.utils.widget_utils import choose_img, edit_image, choose_img_pair, overlay_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sometimes raw images are in .tif stacks, not individual .tif files\n",
    "#optional code block for turning into individual slices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Adjust contrast of images\n",
    "Before doing anything else, we need to adjust the contrast of the raw data. contrast_adjustment blurs the data using a gaussian filter, finds the edges, inverts, and does additional equalization if needed. The user defines the parameters needed using the widgets below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Option 1: Annotations of images, no overlays\n",
    "Some images, such as those of fluorescent nuclei, are relatively easy to annotate. Use the following code blocks to adjust the contrast of those images and save them. For more difficult data, such as cytoplasmic images, you may overlay two images (such as phase and fluorescence) to help guide annotations. To overlay images for annotation, skip to option 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define path to desired raw directory\n",
    "base_dir = \"/gnv_home/data/contrast_test/pics181220\"\n",
    "raw_folder = \"pos1\"\n",
    "identifier = \"test0\"\n",
    "\n",
    "dirpath = os.path.join(base_dir, raw_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose which raw image you would like to use to test on the contrast adjustment\n",
    "choose_raw = interactive(choose_img, name=get_img_names(dirpath), dirpath =fixed(dirpath));\n",
    "choose_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Test with choosen image to fix adjustment parameters\n",
    "img = imread(choose_image.result)\n",
    "edit_raw = interactive(edit_image, image=fixed(img), blur=(0.0,4,0.1), gamma_adjust=(0.1,4,0.1), sobel_factor=(10,10000,100));\n",
    "edit_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# With choosen parameters, process all the raw data in the folder\n",
    "contrast(base_dir, raw_folder, identifier, gaussian_sigma, hist, adapthist, gamma)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Option 2: Overlay two images types for annotation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define path to desired raw and overlay directories\n",
    "base_dir = \"/gnv_home/data/contrast_overlay_test\"\n",
    "raw_folder = \"FITC\"\n",
    "overlay_folder = \"phase\"\n",
    "identifier = \"overlay_test_eq\"\n",
    "\n",
    "raw_path = os.path.join(base_dir, raw_folder)\n",
    "overlay_path = os.path.join(base_dir, overlay_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#pick a matched pair of images to adjust contrast\n",
    "#choose representative images for best results\n",
    "max_frame = len(get_img_names(raw_path))\n",
    "\n",
    "choose_pair = interactive(choose_img_pair, frame = (0, max_frame, 1), raw_dir = fixed(raw_path), overlay_dir = fixed(overlay_path), continuous_update = False);\n",
    "choose_pair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#adjust raw image\n",
    "raw_img = imread(choose_pair.result[0])\n",
    "edit_raw = interactive(edit_image, image=fixed(raw_img), blur=(0.0,4,0.1), gamma_adjust=(0.1,4,0.1), sobel_factor=(10,10000,100));\n",
    "edit_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#adjust overlay image\n",
    "overlay_img = imread(choose_pair.result[1])\n",
    "edit_overlay = interactive(edit_image, image=fixed(overlay_img), blur=(0.0,4,0.1), gamma_adjust=(0.1,4,0.1), sobel_factor=(10,10000,100));\n",
    "edit_overlay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#overlay images\n",
    "raw_adjusted = edit_raw.result\n",
    "overlay_adjusted = edit_overlay.result\n",
    "edit_combination = interactive(overlay_images, raw_img = fixed(raw_adjusted), overlay_img =fixed(overlay_adjusted), prop_raw =(0,1.0, 0.1), v_min = (0, 255, 1), v_max = (0, 255, 1))\n",
    "edit_combination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#apply overlay settings to all images in folder\n",
    "#modified images are saved to new folder and do not overwrite originals\n",
    "raw_settings = edit_raw.kwargs\n",
    "overlay_settings = edit_overlay.kwargs\n",
    "combined_settings = edit_combination.kwargs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "adjust_overlay(base_dir, raw_folder, overlay_folder, identifier, raw_settings, overlay_settings, combined_settings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Chop up images into manageable pieces\n",
    "\n",
    "Each full-size image usually has many cells in it. This makes them difficult to fully annotate! For ease of annotation (and better results), each frame is chopped up into smaller, overlapping frames, ultimately creating a set of movies. \n",
    "\n",
    "These smaller movies can be made with overlapping edges, making it easier to stitch annotations together into one large annotated movie (in the post-annotation pipeline). A large overlap will result in redundant annotations.\n",
    "\n",
    "Even if you want to process the full-sized image, run the chopper with num_segments of 1. The montage makers are written to run on the output of the chopper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# base_direc = \"/home/geneva/Desktop/Nb_testing/\"\n",
    "# raw_direc = os.path.join(base_direc, \"MouseBrain_s7_nuclear\")\n",
    "# identifier = \"MouseBrain_s7_nuc\"\n",
    "\n",
    "num_x_segments = 4\n",
    "num_y_segments = 4\n",
    "overlap_perc = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_direc = \"/gnv_home/data/contrast_overlay_test/FITC_overlay_phase_1\"\n",
    "overlapping_crop_dir(raw_direc, identifier, num_x_segments, num_y_segments, overlap_perc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Make into montages\n",
    "multiple_montage_maker is written to run on the output of the chopper, ie the folder where each chopped movie folder is saved. It will make montages of each subfolder according to the variables specified. It will make more than one montage per subfolder if there are enough frames to do so.\n",
    "\n",
    "The variables used in multiple_montage_maker are saved in a JSON file so they can be reused in post-annotation processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "montage_len = 10\n",
    "\n",
    "direc = raw_direc + \"_chopped_\" + str(num_x_segments) + \"_\" + str(num_y_segments)\n",
    "#direc = \"/home/geneva/Desktop/Nb_testing/nuclear_test_chopped_4_4\"\n",
    "\n",
    "save_direc = os.path.join(base_dir, identifier + \"_montages_\" + str(num_x_segments) + \"_\" + str(num_y_segments))\n",
    "#save_direc = \"/home/geneva/Desktop/Nb_testing/montages\"\n",
    "\n",
    "log_direc = os.path.join(base_dir, \"json_logs\")\n",
    "\n",
    "row_length = 10\n",
    "x_buffer = 20\n",
    "y_buffer = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "multiple_montage_maker(montage_len, direc, save_direc, identifier, \n",
    "                       num_x_segments, num_y_segments, row_length, x_buffer, y_buffer, log_direc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Upload to Figure Eight\n",
    "Now that the images are processed into montages, they need to be uploaded to an AWS bucket and submitted to Figure Eight. This involves uploading the files to AWS, making a CSV file with the links to the uploaded images, and using that CSV file to create a Figure Eight job."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Upload files to AWS\n",
    "aws_upload will look for image files in the specified directory (folder_to_upload, set by default to be wherever the output of multiple_montage_maker was saved) and upload them into a bucket.\n",
    "\n",
    "For the Van Valen lab, the default bucket is \"figure-eight-deepcell\" and keys (aws_folder + file names) correspond to the file structure of our data server.\n",
    "\n",
    "aws_upload returns a list of the urls to which images were uploaded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#import os\n",
    "\n",
    "bucket_name = \"figure-eight-deepcell\" #default\n",
    "aws_folder = \"Ed/3T3/set0/cyto_test\"\n",
    "#folder_to_upload = save_direc #usually .../montages\n",
    "folder_to_upload = \"/gnv_home/data/contrast_overlay_test/contrast_test_examples\"\n",
    "\n",
    "uploaded_montages = aws_upload(bucket_name, aws_folder, folder_to_upload)\n",
    "\n",
    "#os.path.join(\"https://s3.us-east-2.amazonaws.com\", bucket_name, aws_folder)\n",
    "#print(uploaded_montages)\n",
    "#from io_utils import get_img_names\n",
    "#imgs_to_upload = get_img_names(folder_to_upload)\n",
    "#for index, img in enumerate(imgs_to_upload):\n",
    "#    print(img)\n",
    "#    print(os.path.join(folder_to_upload, img))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make CSV file\n",
    "Figure Eight jobs can be created easily by using a CSV file where each row contains information about one task. For our jobs, each row has the link to the location of one montage, and information about that montage (currently, just the \"identifier\" specified at the beginning of the pipeline). The CSV file is saved as \"identifier\".csv in a folder that only holds CSVs. CSV folders are usually in cell-type directories, so identifiers should be able to distinguish between sets, parts, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#identifier = \"test\"\n",
    "csv_direc = os.path.join(base_dir, \"CSV\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_maker(uploaded_montages, identifier, csv_direc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Figure Eight job\n",
    "The Figure Eight API allows us to create a new job and upload data to it from this notebook. However, since our jobs don't include required test questions, editing job information such as the title of the job must be done via the website. This section of the notebook uses the API to create a job and upload data to it, then reminds the user to finish editing the job on the website.\n",
    "\n",
    "Some sample job IDs to copy are provided below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#job_id_to_copy = 1344258 #Elowitz timelapse RFP pilot\n",
    "job_id_to_copy = 1346216 #Deepcell MouseBrain 3x5\n",
    "#job_id_to_copy = 1306431 #Deepcell overlapping Mibi\n",
    "#job_id_to_copy = 1292179 #Deepcell HEK\n",
    "#job_id_to_copy ="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dcde.pre_annotation.fig_eight_upload import fig_eight\n",
    "\n",
    "fig_eight(csv_direc, identifier, job_id_to_copy)"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
