{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Prep for Crowd Annotation Pipeline\n",
    "\n",
    "1. Collect raw data \n",
    "2. Adjust contrast of images\n",
    "3. Chop up images into manageable pieces\n",
    "4. Make into montages\n",
    "5. Upload to Figure8\n",
    "\n",
    "Files are named by these scripts such that the code blocks can run back-to-back with minimal input. For this reason, it is recommended that users run through the whole pipeline before processing another set of images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import statements\n",
    "from __future__ import absolute_import\n",
    "\n",
    "import os\n",
    "from io import BytesIO\n",
    "from IPython.display import Image\n",
    "from ipywidgets import interact, interactive, fixed\n",
    "import matplotlib as mpl\n",
    "from skimage import data, filters, io, img_as_uint\n",
    "import numpy as np\n",
    "import skimage as sk\n",
    "from skimage import filters\n",
    "from scipy import ndimage\n",
    "import scipy\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.ndimage as ndi\n",
    "\n",
    "%matplotlib inline\n",
    "dirpath = r'test/pics/pics181220/raw'\n",
    "# filepath = os.path.join(dirpath, filename)\n",
    "# print(filepath)\n",
    "#from dcde.pre_annotation.contrast_adjustment import contrast\n",
    "\n",
    "#import ipywidgets as widgets\n",
    "from ipywidgets import interact\n",
    "from skimage.io import imread\n",
    "\n",
    "from dcde.pre_annotation.montage_makers import montage_maker, multiple_montage_maker\n",
    "from dcde.pre_annotation.overlapping_chopper import overlapping_crop_dir\n",
    "from dcde.pre_annotation.aws_upload import aws_upload, upload\n",
    "from dcde.pre_annotation.montage_to_csv import csv_maker\n",
    "from dcde.pre_annotation.fig_eight_upload import fig_eight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sometimes raw images are in .tif stacks, not individual .tif files\n",
    "#optional code block for turning into individual slices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Adjust contrast of images\n",
    "description of contrast_adjustment.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Chop up images into manageable pieces\n",
    "\n",
    "Each full-size image usually has many cells in it. This makes them difficult to fully annotate! For ease of annotation (and better results), each frame is chopped up into smaller, overlapping frames, ultimately creating a set of movies. \n",
    "\n",
    "These smaller movies can be made with overlapping edges, making it easier to stitch annotations together into one large annotated movie (in the post-annotation pipeline). A large overlap will result in redundant annotations.\n",
    "\n",
    "Even if you want to process the full-sized image, run the chopper with num_segments of 1. The montage makers are written to run on the output of the chopper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_direc = \"/data/data/cells/MouseBrain/generic/set_test/MouseBrain_nuc_adjusted\"\n",
    "identifier = \"test\"\n",
    "num_x_segments = 5\n",
    "num_y_segments = 5\n",
    "overlap_perc = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Image Size:  (1024, 1024)\n",
      "Correct? (y/n): y\n",
      "Processing...\n",
      "Cropped files saved to /data/data/cells/MouseBrain/generic/set_test/MouseBrain_nuc_adjusted_chopped_5_5\n"
     ]
    }
   ],
   "source": [
    "overlapping_crop_dir(raw_direc, identifier, num_x_segments, num_y_segments, overlap_perc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Make into montages\n",
    "multiple_montage_maker is written to run on the output of the chopper, ie the folder where each chopped movie folder is saved. It will make montages of each subfolder according to the variables specified. It will make more than one montage per subfolder if there are enough frames to do so.\n",
    "\n",
    "The variables used in multiple_montage_maker are saved in a JSON file so they can be reused in post-annotation processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "montage_len = 15\n",
    "\n",
    "direc = raw_direc + \"_chopped_\" + str(num_x_segments) + \"_\" + str(num_y_segments)\n",
    "#direc = \"/home/geneva/Desktop/Nb_testing/nuclear_test_chopped_4_4\"\n",
    "\n",
    "save_direc = os.path.join(os.path.dirname(direc), identifier + \"_montages_\" + str(num_x_segments) + \"_\" + str(num_y_segments))\n",
    "#save_direc = \"/home/geneva/Desktop/Nb_testing/montages\"\n",
    "\n",
    "row_length = 5\n",
    "x_buffer = 5\n",
    "y_buffer = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now montaging images from: test_x_00_y_00\n",
      "You will be able to make 2 montages from this movie.\n",
      "The last 8 frames will not be used in a montage. \n",
      "\n",
      "Now montaging images from: test_x_01_y_00\n",
      "You will be able to make 2 montages from this movie.\n",
      "The last 8 frames will not be used in a montage. \n",
      "\n",
      "Now montaging images from: test_x_02_y_00\n",
      "You will be able to make 2 montages from this movie.\n",
      "The last 8 frames will not be used in a montage. \n",
      "\n",
      "Now montaging images from: test_x_03_y_00\n",
      "You will be able to make 2 montages from this movie.\n",
      "The last 8 frames will not be used in a montage. \n",
      "\n",
      "Now montaging images from: test_x_04_y_00\n",
      "You will be able to make 2 montages from this movie.\n",
      "The last 8 frames will not be used in a montage. \n",
      "\n",
      "Now montaging images from: test_x_00_y_01\n",
      "You will be able to make 2 montages from this movie.\n",
      "The last 8 frames will not be used in a montage. \n",
      "\n",
      "Now montaging images from: test_x_01_y_01\n",
      "You will be able to make 2 montages from this movie.\n",
      "The last 8 frames will not be used in a montage. \n",
      "\n",
      "Now montaging images from: test_x_02_y_01\n",
      "You will be able to make 2 montages from this movie.\n",
      "The last 8 frames will not be used in a montage. \n",
      "\n",
      "Now montaging images from: test_x_03_y_01\n",
      "You will be able to make 2 montages from this movie.\n",
      "The last 8 frames will not be used in a montage. \n",
      "\n",
      "Now montaging images from: test_x_04_y_01\n",
      "You will be able to make 2 montages from this movie.\n",
      "The last 8 frames will not be used in a montage. \n",
      "\n",
      "Now montaging images from: test_x_00_y_02\n",
      "You will be able to make 2 montages from this movie.\n",
      "The last 8 frames will not be used in a montage. \n",
      "\n",
      "Now montaging images from: test_x_01_y_02\n",
      "You will be able to make 2 montages from this movie.\n",
      "The last 8 frames will not be used in a montage. \n",
      "\n",
      "Now montaging images from: test_x_02_y_02\n",
      "You will be able to make 2 montages from this movie.\n",
      "The last 8 frames will not be used in a montage. \n",
      "\n",
      "Now montaging images from: test_x_03_y_02\n",
      "You will be able to make 2 montages from this movie.\n",
      "The last 8 frames will not be used in a montage. \n",
      "\n",
      "Now montaging images from: test_x_04_y_02\n",
      "You will be able to make 2 montages from this movie.\n",
      "The last 8 frames will not be used in a montage. \n",
      "\n",
      "Now montaging images from: test_x_00_y_03\n",
      "You will be able to make 2 montages from this movie.\n",
      "The last 8 frames will not be used in a montage. \n",
      "\n",
      "Now montaging images from: test_x_01_y_03\n",
      "You will be able to make 2 montages from this movie.\n",
      "The last 8 frames will not be used in a montage. \n",
      "\n",
      "Now montaging images from: test_x_02_y_03\n",
      "You will be able to make 2 montages from this movie.\n",
      "The last 8 frames will not be used in a montage. \n",
      "\n",
      "Now montaging images from: test_x_03_y_03\n",
      "You will be able to make 2 montages from this movie.\n",
      "The last 8 frames will not be used in a montage. \n",
      "\n",
      "Now montaging images from: test_x_04_y_03\n",
      "You will be able to make 2 montages from this movie.\n",
      "The last 8 frames will not be used in a montage. \n",
      "\n",
      "Now montaging images from: test_x_00_y_04\n",
      "You will be able to make 2 montages from this movie.\n",
      "The last 8 frames will not be used in a montage. \n",
      "\n",
      "Now montaging images from: test_x_01_y_04\n",
      "You will be able to make 2 montages from this movie.\n",
      "The last 8 frames will not be used in a montage. \n",
      "\n",
      "Now montaging images from: test_x_02_y_04\n",
      "You will be able to make 2 montages from this movie.\n",
      "The last 8 frames will not be used in a montage. \n",
      "\n",
      "Now montaging images from: test_x_03_y_04\n",
      "You will be able to make 2 montages from this movie.\n",
      "The last 8 frames will not be used in a montage. \n",
      "\n",
      "Now montaging images from: test_x_04_y_04\n",
      "You will be able to make 2 montages from this movie.\n",
      "The last 8 frames will not be used in a montage. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "multiple_montage_maker(montage_len, direc, save_direc, identifier, \n",
    "                       num_x_segments, num_y_segments, row_length, x_buffer, y_buffer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Upload to Figure Eight\n",
    "Now that the images are processed into montages, they need to be uploaded to an AWS bucket and submitted to Figure Eight. This involves uploading the files to AWS, making a CSV file with the links to the uploaded images, and using that CSV file to create a Figure Eight job."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Upload files to AWS\n",
    "aws_upload will look for image files in the specified directory (folder_to_upload, set by default to be wherever the output of multiple_montage_maker was saved) and upload them into a bucket.\n",
    "\n",
    "For the Van Valen lab, the default bucket is \"figure-eight-deepcell\" and keys (aws_folder + file names) correspond to the file structure of our data server.\n",
    "\n",
    "aws_upload returns a list of the urls to which images were uploaded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What is your AWS access key id? ········\n",
      "What is your AWS secret access key id? ········\n",
      "Connected to AWS\n",
      "/data/data/cells/MouseBrain/generic/set_test/test_montages_5_5/test_x_0_y_0_montage_0.png  849622 / 849622.0  (100.00%)\n",
      "\n",
      "/data/data/cells/MouseBrain/generic/set_test/test_montages_5_5/test_x_0_y_0_montage_1.png  890794 / 890794.0  (100.00%)\n",
      "\n",
      "/data/data/cells/MouseBrain/generic/set_test/test_montages_5_5/test_x_0_y_1_montage_0.png  967973 / 967973.0  (100.00%)\n",
      "\n",
      "/data/data/cells/MouseBrain/generic/set_test/test_montages_5_5/test_x_0_y_1_montage_1.png  975484 / 975484.0  (100.00%)\n",
      "\n",
      "/data/data/cells/MouseBrain/generic/set_test/test_montages_5_5/test_x_0_y_2_montage_0.png  969750 / 969750.0  (100.00%)\n",
      "\n",
      "/data/data/cells/MouseBrain/generic/set_test/test_montages_5_5/test_x_0_y_2_montage_1.png  865454 / 865454.0  (100.00%)\n",
      "\n",
      "/data/data/cells/MouseBrain/generic/set_test/test_montages_5_5/test_x_0_y_3_montage_0.png  956657 / 956657.0  (100.00%)\n",
      "\n",
      "/data/data/cells/MouseBrain/generic/set_test/test_montages_5_5/test_x_0_y_3_montage_1.png  996017 / 996017.0  (100.00%)\n",
      "\n",
      "/data/data/cells/MouseBrain/generic/set_test/test_montages_5_5/test_x_0_y_4_montage_0.png  765648 / 765648.0  (100.00%)\n",
      "\n",
      "/data/data/cells/MouseBrain/generic/set_test/test_montages_5_5/test_x_0_y_4_montage_1.png  886460 / 886460.0  (100.00%)\n",
      "\n",
      "/data/data/cells/MouseBrain/generic/set_test/test_montages_5_5/test_x_1_y_0_montage_0.png  914641 / 914641.0  (100.00%)\n",
      "\n",
      "/data/data/cells/MouseBrain/generic/set_test/test_montages_5_5/test_x_1_y_0_montage_1.png  1027899 / 1027899.0  (100.00%)\n",
      "\n",
      "/data/data/cells/MouseBrain/generic/set_test/test_montages_5_5/test_x_1_y_1_montage_0.png  1038100 / 1038100.0  (100.00%)\n",
      "\n",
      "/data/data/cells/MouseBrain/generic/set_test/test_montages_5_5/test_x_1_y_1_montage_1.png  1122465 / 1122465.0  (100.00%)\n",
      "\n",
      "/data/data/cells/MouseBrain/generic/set_test/test_montages_5_5/test_x_1_y_2_montage_0.png  1046067 / 1046067.0  (100.00%)\n",
      "\n",
      "/data/data/cells/MouseBrain/generic/set_test/test_montages_5_5/test_x_1_y_2_montage_1.png  1081856 / 1081856.0  (100.00%)\n",
      "\n",
      "/data/data/cells/MouseBrain/generic/set_test/test_montages_5_5/test_x_1_y_3_montage_0.png  1019579 / 1019579.0  (100.00%)\n",
      "\n",
      "/data/data/cells/MouseBrain/generic/set_test/test_montages_5_5/test_x_1_y_3_montage_1.png  1068753 / 1068753.0  (100.00%)\n",
      "\n",
      "/data/data/cells/MouseBrain/generic/set_test/test_montages_5_5/test_x_1_y_4_montage_0.png  957394 / 957394.0  (100.00%)\n",
      "\n",
      "/data/data/cells/MouseBrain/generic/set_test/test_montages_5_5/test_x_1_y_4_montage_1.png  1015767 / 1015767.0  (100.00%)\n",
      "\n",
      "/data/data/cells/MouseBrain/generic/set_test/test_montages_5_5/test_x_2_y_0_montage_0.png  999010 / 999010.0  (100.00%)\n",
      "\n",
      "/data/data/cells/MouseBrain/generic/set_test/test_montages_5_5/test_x_2_y_0_montage_1.png  1026237 / 1026237.0  (100.00%)\n",
      "\n",
      "/data/data/cells/MouseBrain/generic/set_test/test_montages_5_5/test_x_2_y_1_montage_0.png  1217236 / 1217236.0  (100.00%)\n",
      "\n",
      "/data/data/cells/MouseBrain/generic/set_test/test_montages_5_5/test_x_2_y_1_montage_1.png  1144954 / 1144954.0  (100.00%)\n",
      "\n",
      "/data/data/cells/MouseBrain/generic/set_test/test_montages_5_5/test_x_2_y_2_montage_0.png  1188155 / 1188155.0  (100.00%)\n",
      "\n",
      "/data/data/cells/MouseBrain/generic/set_test/test_montages_5_5/test_x_2_y_2_montage_1.png  1037526 / 1037526.0  (100.00%)\n",
      "\n",
      "/data/data/cells/MouseBrain/generic/set_test/test_montages_5_5/test_x_2_y_3_montage_0.png  1035295 / 1035295.0  (100.00%)\n",
      "\n",
      "/data/data/cells/MouseBrain/generic/set_test/test_montages_5_5/test_x_2_y_3_montage_1.png  1147187 / 1147187.0  (100.00%)\n",
      "\n",
      "/data/data/cells/MouseBrain/generic/set_test/test_montages_5_5/test_x_2_y_4_montage_0.png  910205 / 910205.0  (100.00%)\n",
      "\n",
      "/data/data/cells/MouseBrain/generic/set_test/test_montages_5_5/test_x_2_y_4_montage_1.png  884772 / 884772.0  (100.00%)\n",
      "\n",
      "/data/data/cells/MouseBrain/generic/set_test/test_montages_5_5/test_x_3_y_0_montage_0.png  789764 / 789764.0  (100.00%)\n",
      "\n",
      "/data/data/cells/MouseBrain/generic/set_test/test_montages_5_5/test_x_3_y_0_montage_1.png  848032 / 848032.0  (100.00%)\n",
      "\n",
      "/data/data/cells/MouseBrain/generic/set_test/test_montages_5_5/test_x_3_y_1_montage_0.png  994838 / 994838.0  (100.00%)\n",
      "\n",
      "/data/data/cells/MouseBrain/generic/set_test/test_montages_5_5/test_x_3_y_1_montage_1.png  892054 / 892054.0  (100.00%)\n",
      "\n",
      "/data/data/cells/MouseBrain/generic/set_test/test_montages_5_5/test_x_3_y_2_montage_0.png  941436 / 941436.0  (100.00%)\n",
      "\n",
      "/data/data/cells/MouseBrain/generic/set_test/test_montages_5_5/test_x_3_y_2_montage_1.png  942628 / 942628.0  (100.00%)\n",
      "\n",
      "/data/data/cells/MouseBrain/generic/set_test/test_montages_5_5/test_x_3_y_3_montage_0.png  913497 / 913497.0  (100.00%)\n",
      "\n",
      "/data/data/cells/MouseBrain/generic/set_test/test_montages_5_5/test_x_3_y_3_montage_1.png  919539 / 919539.0  (100.00%)\n",
      "\n",
      "/data/data/cells/MouseBrain/generic/set_test/test_montages_5_5/test_x_3_y_4_montage_0.png  887973 / 887973.0  (100.00%)\n",
      "\n",
      "/data/data/cells/MouseBrain/generic/set_test/test_montages_5_5/test_x_3_y_4_montage_1.png  751682 / 751682.0  (100.00%)\n",
      "\n",
      "/data/data/cells/MouseBrain/generic/set_test/test_montages_5_5/test_x_4_y_0_montage_0.png  656961 / 656961.0  (100.00%)\n",
      "\n",
      "/data/data/cells/MouseBrain/generic/set_test/test_montages_5_5/test_x_4_y_0_montage_1.png  726816 / 726816.0  (100.00%)\n",
      "\n",
      "/data/data/cells/MouseBrain/generic/set_test/test_montages_5_5/test_x_4_y_1_montage_0.png  771420 / 771420.0  (100.00%)\n",
      "\n",
      "/data/data/cells/MouseBrain/generic/set_test/test_montages_5_5/test_x_4_y_1_montage_1.png  794086 / 794086.0  (100.00%)\n",
      "\n",
      "/data/data/cells/MouseBrain/generic/set_test/test_montages_5_5/test_x_4_y_2_montage_0.png  669530 / 669530.0  (100.00%)\n",
      "\n",
      "/data/data/cells/MouseBrain/generic/set_test/test_montages_5_5/test_x_4_y_2_montage_1.png  740605 / 740605.0  (100.00%)\n",
      "\n",
      "/data/data/cells/MouseBrain/generic/set_test/test_montages_5_5/test_x_4_y_3_montage_0.png  735886 / 735886.0  (100.00%)\n",
      "\n",
      "/data/data/cells/MouseBrain/generic/set_test/test_montages_5_5/test_x_4_y_3_montage_1.png  853019 / 853019.0  (100.00%)\n",
      "\n",
      "/data/data/cells/MouseBrain/generic/set_test/test_montages_5_5/test_x_4_y_4_montage_0.png  695404 / 695404.0  (100.00%)\n",
      "\n",
      "/data/data/cells/MouseBrain/generic/set_test/test_montages_5_5/test_x_4_y_4_montage_1.png  722281 / 722281.0  (100.00%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#import os\n",
    "\n",
    "bucket_name = \"figure-eight-deepcell\" #default\n",
    "aws_folder = \"MouseBrain/test\"\n",
    "folder_to_upload = save_direc #usually .../montages\n",
    "#data_to_upload = \"/home/geneva/Desktop/Nb_testing/montages/\"\n",
    "\n",
    "uploaded_montages = aws_upload(bucket_name, aws_folder, folder_to_upload)\n",
    "\n",
    "#os.path.join(\"https://s3.us-east-2.amazonaws.com\", bucket_name, aws_folder)\n",
    "#print(uploaded_montages)\n",
    "#from io_utils import get_img_names\n",
    "#imgs_to_upload = get_img_names(folder_to_upload)\n",
    "#for index, img in enumerate(imgs_to_upload):\n",
    "#    print(img)\n",
    "#    print(os.path.join(folder_to_upload, img))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make CSV file\n",
    "Figure Eight jobs can be created easily by using a CSV file where each row contains information about one task. For our jobs, each row has the link to the location of one montage, and information about that montage (currently, just the \"identifier\" specified at the beginning of the pipeline). The CSV file is saved as \"identifier\".csv in a folder that only holds CSVs. CSV folders are usually in cell-type directories, so identifiers should be able to distinguish between sets, parts, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#identifier = \"test\"\n",
    "csv_direc = \"temp_files\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_maker(uploaded_montages, identifier, csv_direc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Figure Eight job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#job_id_to_copy = 1344258 #Elowitz timelapse RFP pilot\n",
    "job_id_to_copy = 1346216 #Deepcell MouseBrain 3x5\n",
    "#job_id_to_copy = 1306431 #Deepcell overlapping Mibi\n",
    "#job_id_to_copy = 1292179 #Deepcell HEK\n",
    "#job_id_to_copy ="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Figure eight api key? ········\n",
      "200\n",
      "New job ID is: 1353520\n",
      "Added data\n",
      "Head over to the Figure Eight website to change the name of the job, review it, then contact the success manager so they can launch this job.\n"
     ]
    }
   ],
   "source": [
    "from dcde.pre_annotation.fig_eight_upload import fig_eight\n",
    "\n",
    "fig_eight(csv_direc, identifier, job_id_to_copy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "enter your API key········\n"
     ]
    }
   ],
   "source": [
    "# curl -X GET https://api.figure-eight.com/v1/jobs/{job_id}/copy.json?key={api_key}\n",
    "#import requests\n",
    "#from getpass import getpass\n",
    "\n",
    "#API_key = getpass(\"enter your API key\")\n",
    "#inputs = {\"key\" : API_key}\n",
    "#inputs\n",
    "#url = \"https://api.figure-eight.com/v1/jobs/1344258/copy.json?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 1351927,\n",
       " 'options': {'mail_to': 'gemiller@caltech.edu',\n",
       "  'flag_on_rate_limit': True,\n",
       "  'include_unfinished': True,\n",
       "  'logical_aggregation': True,\n",
       "  'critical_webhook': False,\n",
       "  'req_ttl_in_seconds': 7200,\n",
       "  'front_load': False},\n",
       " 'title': '(Shilpa Only) Deepcell Rfp Timelapse S0 - Segmentation Of Cells In Microscope Images Over Time (Pilot)',\n",
       " 'secret': 'HYSPT+E/FFZcsmglmfOHdDcUEGki8VzEs0XHHhnqwnxz',\n",
       " 'project_number': 'PN2135',\n",
       " 'alias': None,\n",
       " 'judgments_per_unit': 1,\n",
       " 'units_per_assignment': 1,\n",
       " 'pages_per_assignment': 1,\n",
       " 'max_judgments_per_worker': None,\n",
       " 'gold_per_assignment': 1,\n",
       " 'minimum_account_age_seconds': None,\n",
       " 'execution_mode': 'worker_ui_remix',\n",
       " 'payment_cents': 100,\n",
       " 'design_verified': True,\n",
       " 'public_data': True,\n",
       " 'variable_judgments_mode': 'none',\n",
       " 'max_judgments_per_unit': None,\n",
       " 'expected_judgments_per_unit': None,\n",
       " 'min_unit_confidence': None,\n",
       " 'units_remain_finalized': None,\n",
       " 'auto_order_timeout': None,\n",
       " 'auto_order_threshold': 0,\n",
       " 'completed_at': None,\n",
       " 'state': 'unordered',\n",
       " 'auto_order': False,\n",
       " 'webhook_uri': None,\n",
       " 'send_judgments_webhook': None,\n",
       " 'language': 'en',\n",
       " 'minimum_requirements': None,\n",
       " 'desired_requirements': None,\n",
       " 'max_work_per_network': None,\n",
       " 'copied_from': 1344258,\n",
       " 'created_at': '2019-02-21T23:22:14+00:00',\n",
       " 'updated_at': '2019-02-21T23:22:14+00:00',\n",
       " 'included_countries': [],\n",
       " 'excluded_countries': [],\n",
       " 'instructions': '<p><span style=\"text-align: initial;\"><strong><u>Time-lapse</u></strong></span><strong><u>&nbsp;Cell Annotation</u></strong></p>\\n<p><span style=\"color: rgb(0, 0, 0);\"><strong>Overview:&nbsp;</strong>In this task you will be asked to individually label cells in frames of a microscopy video.</span></p>\\n<p><strong style=\"color: rgb(0, 0, 0);\">Background:&nbsp;</strong>Our group is in the process of writing a computer program to automatically identify and track the movement of individual cells in microscope images. To help us do this, we\\'re asking you to help create annotated datasets where single cells are manually identified. We can then feed this into the computer program to teach it how to accurately identify cells by itself. The program developed using the data you are annotating will be used in other research laboratories to study a range of topics, including viruses and cancer cells. <u>The software we create is only as good as the data used to create it, so accuracy in your annotations is extremely important.&nbsp;</u></p>\\n<p>In this job, each image consists of a sequence of snapshots in time, ordered from left to right, top to bottom. Every image in this sequence needs to be annotated. An example of what the image should look like before and after your annotation is shown below:</p>\\n<p><img src=\"https://s3.amazonaws.com/crowdflower-make-cloud/images%2F1533207319808-pic5.png\" style=\"width: 663px; height: 383.06665542602536px;\" class=\"fr-fic fr-dib\" /></p>\\n<p><br /></p>\\n<p><strong><u>Annotation Instructions:</u></strong></p>\\n<p>You must stick to the following rules when labelling cells (further explanations are provided below):</p>\\n<p><img src=\"https://s3.amazonaws.com/crowdflower-make-cloud/images%2F1533063612054-Screen+Shot+2018-07-31+at+11.59.45.png\" style=\"width: 731px; height: 441.0253411787975px;\" class=\"fr-fic fr-dib\" /></p>\\n<p>One good strategy to use would be to start from a specific region and follow one cell at a time across all the frames. &nbsp;After the first cell is colored the same across all the frames it is present in, go back and choose a neighboring one. &nbsp;Continue doing this to build up to the entire frame, one cell at a time (<u><span style=\"color: rgb(209, 72, 65);\"><strong>never</strong></span> reuse colors for different cells, even if the cell disappears before the end of the frames)</u>.</p>\\n<p><br /><strong><u>Annotation Technique</u></strong></p>\\n<p><span style=\"color: rgb(0, 0, 0);\">Zoom in on a frame and use the brush tool to outline the cell and fill in the middle, changing the brush size using the slider. Use the eraser tool to correct mistakes.&nbsp;</span></p>\\n<p><span style=\"color: rgb(0, 0, 0);\">OR</span></p>\\n<table style=\"width: 100%;\"><tbody><tr><td style=\"width: 33.3725%;\">Roughly color the same cell in all panels using the paintbrush tool.</td><td style=\"width: 66.51%;\"><img src=\"https://s3.amazonaws.com/crowdflower-make-cloud/images%2F1533206860216-Screen+Shot+2018-08-02+at+03.46.18.png\" style=\"width: 554px; height: 155.12px;\" class=\"fr-fic fr-dib\" /></td></tr><tr><td style=\"width: 33.3725%;\">Click on the background of the image &nbsp;with the magic tool.</td><td style=\"width: 66.51%;\"><img src=\"https://s3.amazonaws.com/crowdflower-make-cloud/images%2F1533206876669-Screen+Shot+2018-08-02+at+03.46.43.png\" style=\"width: 554px; height: 155.12px;\" class=\"fr-fic fr-dib\" /></td></tr><tr><td style=\"width: 33.3725%;\">Select the eraser tool and click on the colored area that is outside of the cell. This should leave only the cells colored in. <strong>You should now go back and correct the coloring if need be.</strong></td><td style=\"width: 66.51%;\"><img src=\"https://s3.amazonaws.com/crowdflower-make-cloud/images%2F1533206882506-Screen+Shot+2018-08-02+at+03.47.06.png\" style=\"width: 554px; height: 155.12px;\" class=\"fr-fic fr-dib\" /></td></tr></tbody></table>\\n<p><br /></p>\\n<p><br /><strong><u>Examples</u></strong></p>\\n<p><strong><u><br /><img src=\"https://s3.amazonaws.com/crowdflower-make-cloud/images%2F1533236123448-Screen+Shot+2018-08-02+at+11.44.22.png\" style=\"width: 710px; height: 539.5948401162791px;\" class=\"fr-fic fr-dib\" /></u></strong><img src=\"https://s3.amazonaws.com/crowdflower-make-cloud/images%2F1533206711894-Screen+Shot+2018-08-02+at+03.44.22.png\" style=\"width: 714px; height: 399.84px;\" class=\"fr-fic fr-dib\" /></p>\\n<p><br /></p>\\n<p dir=\"ltr\"><strong>Video instructions:&nbsp;</strong>the following is a video explaining the described labelling process.</p>\\n<p><span class=\"fr-video fr-fvc fr-dvi fr-draggable\" contenteditable=\"false\"><iframe src=\"https://www.youtube.com/embed/tvzGl5b1NDw\" width=\"500\" height=\"315\" frameborder=\"0\"></iframe></span></p>\\n',\n",
       " 'cml': '<!--<cml:iframe name=\"annotation\" src=\"https://annotation.figure-eight.com/?settingsName=cells30\" only-if=\"broken_link:unchecked\" id=\"annotation\" gold=\"true\" aggregation=\"agg\"></cml:iframe>-->\\n\\n<cml:pixellabel name=\"annotation\" only-if=\"broken_link:unchecked\"/>\\n\\n<cml:checkbox name=\"broken_link\" label=\"Image does not load\" default=\"false\" aggregation=\"agg\" gold=\"true\"></cml:checkbox>',\n",
       " 'js': '',\n",
       " 'css': '',\n",
       " 'confidence_fields': ['annotation', 'broken_link'],\n",
       " 'gold': {'broken_link': 'broken_link_gold'},\n",
       " 'units_count': 0,\n",
       " 'golds_count': 0,\n",
       " 'judgments_count': 0,\n",
       " 'support_email': 'gemiller@caltech.edu',\n",
       " 'worker_ui_remix': True,\n",
       " 'crowd_costs': 0.0,\n",
       " 'quiz_mode_enabled': False,\n",
       " 'completed': False,\n",
       " 'fields': {'annotation': 'all', 'broken_link': 'agg'},\n",
       " 'order_approved': False,\n",
       " 'message': {'success': 'Job successfully copied. You may add data using one of the methods above.'}}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#r = requests.get(url, params=inputs)\n",
    "#r.json()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1351927"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r.json()['id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
