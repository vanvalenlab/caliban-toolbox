{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Prep for Crowd Annotation Pipeline - 2D data\n",
    "\n",
    "2D data refers to data that doesn't need to be tracked across time or space.\n",
    "\n",
    "1. Collect raw data \n",
    "2. Adjust contrast of images\n",
    "3. Chop up images into manageable pieces\n",
    "4. Upload to Figure8\n",
    "\n",
    "Files are named by these scripts such that the code blocks can run back-to-back with minimal input. For this reason, it is recommended that users run through the whole pipeline before processing another set of images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import statements\n",
    "from __future__ import absolute_import\n",
    "\n",
    "import os\n",
    "\n",
    "from ipywidgets import fixed, interactive\n",
    "from imageio import imread\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "from deepcell_toolbox.pre_annotation.overlapping_chopper import overlapping_crop_dir\n",
    "from deepcell_toolbox.pre_annotation.aws_upload import aws_upload, upload\n",
    "from deepcell_toolbox.pre_annotation.montage_to_csv import csv_maker\n",
    "from deepcell_toolbox.pre_annotation.fig_eight_upload import fig_eight\n",
    "from deepcell_toolbox.pre_annotation.contrast_adjustment import adjust_folder, adjust_overlay\n",
    "\n",
    "from deepcell_toolbox.utils.io_utils import get_img_names\n",
    "from deepcell_toolbox.utils.widget_utils import choose_img, edit_image, choose_img_pair, overlay_images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "raw_mimetype": "text/markdown"
   },
   "source": [
    "### Select base directory\n",
    "\n",
    "\"base_dir\" is a directory where several subfolders will be created to hold intermediate processed images and files. For example, at the start of this pipeline, \"/home/gnv/data/example\" might hold a few folders of images (different channels of the same dataset). By the end of this pipeline, it will also hold:\n",
    " - a folder for contrast-adjusted images \n",
    " - a folder for sub-images\n",
    " - a folder that contains json files (store information about variables used to process images)\n",
    " - a folder that contains a CSV file to upload to Figure Eight\n",
    " \n",
    "If the images to process are static, choose is_2D = True. This will affect how processed files are named throughout the pipeline. If images are of timelapse videos or have z-stacks, choose is_2D = False. Images saved with 3D naming conventions can be used to display frame context to Figure Eight annotators."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define path to desired base directory\n",
    "base_dir = \"/gnv_home/data/HPA/fig8/\"\n",
    "is_2D = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sometimes raw images are in .tif stacks, not individual .tif files\n",
    "#optional code block for turning into individual slices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Adjust contrast of images\n",
    "Before doing anything else, we need to adjust the contrast of the raw data. The following section of this notebook allows the user to interactively choose how the raw images will be processed. The user should adjust the images to make them the most clear for annotators; these contrast-adjustment images will only be used for annotation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Option 1: Annotations of images, no overlays\n",
    "Some images, such as those of fluorescent nuclei, are relatively easy to annotate. Use the following code blocks to adjust the contrast of those images and save them. For more difficult data, such as cytoplasmic images, you may overlay two images (such as phase and fluorescence) to help guide annotators. To overlay images for annotation, skip to option 2.\n",
    "\n",
    "This widget will allow the user to adjust the following settings, then apply them to a directory of images:\n",
    " - \"blur\" changes a gaussian filter that blurs or sharpens the image\n",
    " - \"sobel_toggle\" determines if a sobel filter is applied on top of the original image; if on, the edges of objects in the image will have the highest contrast\n",
    " - \"sobel_factor\" changes how heavily the sobel filter is applied to the original image, if \"sobel_toggle\" is on\n",
    " - \"invert_img\"  inverts the intensity range of the image, so that the maximum value becomes the minimum, and vice versa\n",
    " - \"gamma_adjust\" changes the overall brightness of the image without interfering with histogram normalization of the image\n",
    "\n",
    " - \"equalize_hist\" - uses histogram equalization of the whole image to rescale pixel values\n",
    " - \"equalize_adapthist\" - uses histogram equalization applied to local regions of the image to rescale pixel values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_folder = \"raw\"\n",
    "identifier = \"example\"\n",
    "\n",
    "raw_dir = os.path.join(base_dir, raw_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose which raw image you would like to use to test on the contrast adjustment\n",
    "choose_raw = interactive(choose_img, name=get_img_names(raw_dir), dirpath =fixed(raw_dir));\n",
    "choose_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Test with choosen image to fix adjustment parameters\n",
    "img = imread(choose_raw.result)\n",
    "edit_raw = interactive(edit_image, image=fixed(img), blur=(0.0,4,0.1), gamma_adjust=(0.1,4,0.1), sobel_factor=(10,10000,100), v_min = (0, 255, 1), v_max = (0, 255, 1));\n",
    "edit_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# With choosen parameters, process all the raw data in the folder\n",
    "contrast_settings = edit_raw.kwargs\n",
    "\n",
    "#don't need this info to process images and can't be saved in json\n",
    "del contrast_settings['image']\n",
    "\n",
    "adjust_folder(base_dir, raw_folder, identifier, contrast_settings, is_2D)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Option 2: Overlay two images types for annotation\n",
    "First, define the folders where your images can be found. This assumes that the images you want to overlay are in separate subfolders. The directory the contains these subfolders, \"base_dir\", is where contrast adjusted images and subsequent processed images will be saved (each in an appropriate subfolder). The subfolders should contain the same number of images; they are expected to be different channels of the same original image.\n",
    "\n",
    "Next, a widget will load that allows you to scroll through the images contained in the source subfolders. The user can select a pair of images that are representative of the data set.\n",
    "\n",
    "Next, a widget will load that allows the user to adjust image processing settings for the first image in the pair (the \"raw\" image). After you are happy with the image, move on to the next code block; the settings you have determined will be saved.\n",
    " \n",
    "Next, a similar widget will load that allows the user to adjust the image that will be overlaid on the \"raw\" image. Once you are satisfied with this image, move on to the next code block; the settings you have determined will be saved.\n",
    " \n",
    "Next, a widget will load that allows the user to adjust how the images are overlaid. The user can specify the weighting of the overlay, and change the brightness settings of the final image to increase contrast. The two images to be overlaid can be readjusted individually if they need to be, by going back to the previous widgets and changing the settings. Just re-run the overlay widget and the new settings will be loaded.\n",
    " \n",
    "Finally, when you are satisfied with the adjustments made to the individual and overlaid images, running \"adjust_overlay\" will take the last-used settings from each widget, apply them to each image in the subfolders specified, and create an overlaid image. The adjusted images will be saved in a new folder; the original images will not be modified. The folder for the adjusted images will be named {raw}\\_overlay\\_{overlay} to indicate which source folders were combined."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define folders for desired raw and overlay directories\n",
    "#base_dir = \"/gnv_home/data/contrast_overlay_test/test3\"\n",
    "raw_folder = \"ER\"\n",
    "overlay_folder = \"microtubules\"\n",
    "identifier = \"HPA_s0\"\n",
    "\n",
    "raw_path = os.path.join(base_dir, raw_folder)\n",
    "overlay_path = os.path.join(base_dir, overlay_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#pick a matched pair of images to adjust contrast\n",
    "#choose representative images for best results\n",
    "max_frame = len(get_img_names(raw_path))\n",
    "\n",
    "choose_pair = interactive(choose_img_pair, frame = (0, max_frame, 1), raw_dir = fixed(raw_path), overlay_dir = fixed(overlay_path), continuous_update = False);\n",
    "choose_pair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#adjust raw image\n",
    "raw_img = imread(choose_pair.result[0])\n",
    "edit_raw = interactive(edit_image, image=fixed(raw_img), blur=(0.0,4,0.1), gamma_adjust=(0.1,4,0.1), sobel_factor=(10,10000,100), v_min=(0,255,1), v_max=(0,255,1));\n",
    "edit_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#adjust overlay image\n",
    "overlay_img = imread(choose_pair.result[1])\n",
    "edit_overlay = interactive(edit_image, image=fixed(overlay_img), blur=(0.0,4,0.1), gamma_adjust=(0.1,4,0.1), sobel_factor=(10,10000,100), v_min = (0, 255, 1), v_max = (0, 255, 1));\n",
    "edit_overlay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#overlay images\n",
    "raw_adjusted = edit_raw.result\n",
    "overlay_adjusted = edit_overlay.result\n",
    "edit_combination = interactive(overlay_images, raw_img = fixed(raw_adjusted), overlay_img =fixed(overlay_adjusted), prop_raw =(0,1.0, 0.1), v_min = (0, 255, 1), v_max = (0, 255, 1))\n",
    "edit_combination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#apply overlay settings to all images in folder\n",
    "#modified images are saved to new folder and do not overwrite originals\n",
    "raw_settings = edit_raw.kwargs\n",
    "del raw_settings['image']\n",
    "overlay_settings = edit_overlay.kwargs\n",
    "del overlay_settings['image']\n",
    "combined_settings = edit_combination.kwargs\n",
    "del combined_settings['overlay_img']\n",
    "del combined_settings['raw_img']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "adjust_overlay(base_dir, raw_folder, overlay_folder, identifier, raw_settings, overlay_settings, combined_settings, is_2D)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Chop up images into manageable pieces\n",
    "\n",
    "Each full-size image usually has many cells in it. This makes them difficult to fully annotate! For ease of annotation (and better results), each frame is chopped up into smaller, overlapping frames, ultimately creating a set of movies. \n",
    "\n",
    "These smaller movies can be made with overlapping edges, making it easier to stitch annotations together into one large annotated movie (in the post-annotation pipeline). A large overlap will result in redundant annotations. \n",
    "\n",
    "\"is_2D\" toggles between two modes for saving the files; \"is_2D = True\" names the chopped images by image number, then by x and y position, while \"is_2D = False\" saves images by x and y position, then by frame. This helps group relevant images together and provides a naming convention for downstream scripts to use.\n",
    "\n",
    "Even if you want to process the full-sized image, run the chopper with num_segments of 1. This is necessary for downstream scripts to work properly.\n",
    "\n",
    "Information about which settings were used will be stored in a .json file in a folder \"base_dir/json_logs\" for later processing steps to reference, when needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_input_folder = \"raw_contrast_adjusted_part2\"\n",
    "image_input_dir = os.path.join(base_dir, image_input_folder)\n",
    "\n",
    "num_x_segments = 4\n",
    "num_y_segments = 4\n",
    "overlap_perc = 10\n",
    "frame_offset = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "overlapping_crop_dir(image_input_dir, \n",
    "                     identifier, \n",
    "                     num_x_segments, \n",
    "                     num_y_segments, \n",
    "                     overlap_perc, \n",
    "                     frame_offset, \n",
    "                     is_2D)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Upload to Figure Eight\n",
    "Now that the images are processed into subimages, they need to be uploaded to an AWS bucket and submitted to Figure Eight. This involves uploading the files to AWS, making a CSV file with the links to the uploaded images, and using that CSV file to create a Figure Eight job."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Upload files to AWS\n",
    "aws_upload will look for image files in the specified directory (folder_to_upload, set by default to be wherever the output of multiple_montage_maker was saved) and upload them into a bucket. If you don't want to include all of the montages you have made in the figure eight job, move the montages of interest to a new folder and upload that.\n",
    "\n",
    "For the Van Valen lab, the default bucket is \"figure-eight-deepcell\" and keys (aws_folder + file names) correspond to the file structure of our data server.\n",
    "\n",
    "aws_upload returns a list of the urls to which images were uploaded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "bucket_name = \"figure-eight-deepcell\" #default\n",
    "aws_folder = \"HPA/set0\"\n",
    "\n",
    "folder_to_upload = \"/gnv_home/data/HPA/fig8/ER_overlay_microtubules\"\n",
    "\n",
    "#including context for 3D images is recommended but not necessary\n",
    "#including context for 2D images is not recommended and not supported\n",
    "include_context = False\n",
    "\n",
    "uploaded_images, prev_images, next_images = aws_upload(bucket_name, aws_folder, folder_to_upload, include_context)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make CSV file\n",
    "Figure Eight jobs can be created easily by using a CSV file where each row contains information about one task. For our jobs, each row has the link to the location of one montage, and information about that montage (currently, just the \"identifier\" specified at the beginning of the pipeline). The CSV file is saved as {identifier}\\_upload.csv in a folder that only holds CSVs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_dir = os.path.join(base_dir, \"CSV\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_maker(uploaded_images, prev_images, next_images, identifier, csv_dir, include_context)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Figure Eight job\n",
    "The Figure Eight API allows us to create a new job and upload data to it from this notebook. However, since our jobs don't include required test questions, editing job information such as the title of the job must be done via the website. This section of the notebook uses the API to create a job and upload data to it, then reminds the user to finish editing the job on the website.\n",
    "\n",
    "Some sample job IDs to copy are provided below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#job_id_to_copy = 1366009 #E coli phase, adjusted with sobel\n",
    "#job_id_to_copy = 1306431 #Deepcell overlapping Mibi\n",
    "#job_id_to_copy = 1292179 #Deepcell HEK\n",
    "job_id_to_copy = 1371512 #microglia, contains mix of cell types, phase, 100 cell ontology\n",
    "#job_id_to_copy = 1373147 #ISBI GOWT1, 100 cell ontology\n",
    "#job_id_to_copy = 1375187 #ISBI MSC with prev/next display\n",
    "#job_id_to_copy = 1381550 #ISBI PSC (Ch01, p0), prev/next, 100 cell ontology\n",
    "#job_id_to_copy = 1380302 #ISBI U373 Ch01, prev/next, phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_eight(csv_dir, identifier, job_id_to_copy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
